# -*- coding: utf-8 -*-
"""CL 1 Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RCH0cKNhPYB_95GXfzUtlp2ARuvx--fa
"""


import nltk
from nltk import word_tokenize, sent_tokenize
import re
import itertools
from nltk.stem.wordnet import WordNetLemmatizer
import time

import pandas as pd

corpus_df = pd.read_csv("edited_at.csv")


def substitute_Currency(sent):

    tokens = sent.split(" ")
    resolved_sent = ""

    for tok in tokens:
        if(re.search(r"\$", tok)):
            resolved_sent = resolved_sent + " "+tok[1:]+" "+"dollars"
        elif(re.search(r"\₹", tok)):
            resolved_sent = resolved_sent + " "+tok[1:]+" "+"rupees"
        else:
            resolved_sent = resolved_sent + " "+tok

    print(resolved_sent)
    return resolved_sent


def resolve_cc(sentence):

    split_sent = re.split(r"(?:\band\b|\bif\b|\bbut\b|\bso\b)", sentence)

    part1_postag = nltk.pos_tag(word_tokenize(split_sent[0]))
    part2_postag = nltk.pos_tag(word_tokenize(split_sent[1]))

    if any(x not in dict(part1_postag).values() for x in verb_tags):
        return sentence
    else:
        pass
   # > << << << pending >> >>>>>>>>>> >


nltk.download('averaged_perceptron_tagger')

conjunction_keywords = ["and", "but", "if", "then"]
currency_keywords = ["₹", "$"]

Plus_list = ["more", "taller", "longer"]
Minus_list = ["less", "fewer", "shorter"]

verb_tags = ['VBD', 'VBZ', 'VBP', 'VBN', 'VBG', 'VB']
Noun_tags = ['NNP', 'NN']
Prep_tags = ['IN', 'TO']
object_tag = ['NNS', 'NNPS']
pronoun_tags = ['PRP', 'PRP$']

schemas_keys = {}
schemas_keys['Change_Out'] = ["put", "place", "plant", "add",
                              "sell", "distribute", "load", "give", "takes away"]
schemas_keys['Combine'] = ["together", "in all",
                           "combined", "in total", "total", "altogether"]
schemas_keys['Reduction'] = ["eat", "destroy", "spend", "remove", "decrease"]
schemas_keys['Change_In'] = ["take from",
                             "get", "pick", "buy", "borrow", "steal"]
schemas_keys['Increase'] = ["more", "carry", "find"]
schemas_keys['Compare_Plus'] = ["more than", "taller than", "longer than"]
schemas_keys['Compare_Minus'] = ["less than", "fewer than", "shorter than"]

nltk.download('punkt')

for index, row in corpus_df.iterrows():
    question = "how many cards are left?"
    sentences = sent_tokenize(question)

    info = []
    ques = []

    for i, s in enumerate(sentences):
        if(re.search('\?', s)):
            ques.append(s)
        else:
            info.append(s)

    for i, s in enumerate(info):
        if '$' in t or '₹' in s:
            info = substitute_Currency(t)

        if (re.search(r"\band\b|\bif\b|\bbut\b|\bso\b", inf)):
            cc_resovle_sent = resolve_cc(s)

    # print(sentences)
    a = substitute_Currency("he has 10 $ .")
    break
